<!DOCTYPE html>
<html>
  <head>
    <title>Irene Solaiman</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link rel="icon" href="img/i.png" type="image/x-icon">
    <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Montserrat" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="css/research.css">
    <link rel="stylesheet" type="text/css" href="css/topnav.css">
  </head>
  <div class="topnav">
  <!--<a href="worldwork.html">World</a>-->
  <a href="research.html">Research</a>
  <a class="active" href="index.html">Irene Solaiman</a>
  <!--<a href="about.html">About</a>-->
  <a href="fun_stuff.html">Fun Stuff</a>
</div>
  <body>
<h1 class="name">My research</h1>

<br>
<br><br>
<br><br>
    
<h2>AI Research</h2>
<h3><a href="https://arxiv.org/abs/2306.05949" target="_blank">Evaluating the Social Impact of Generative AI Systems in Systems and Society</a></h3>
<h4>A guide and categorization of social impacts that are able to be evaluated across generative AI modalities. We describe social impact categories and how to evaluations in the base technical system, then in people and society.</h4>
<p>Solaiman and Talat et al, <a href="https://arxiv.org/abs/2306.05949" target="_blank">Evaluating the Social Impact of Generative AI Systems in Systems and Society</a>, preprint, 2023.</p>

    
<h3><a href="https://arxiv.org/abs/2302.04844" target="_blank">The Gradient of Generative AI Release: Methods and Considerations</a></h3>
<h4>A framework to assess six levels of access to generative AI systems, analysis of past release methods and tensions, and enumerated safety controls and guardrails for generative systems and necessary investments to improve future releases. Accepted to FAccT 2023.</h4>
<p>Solaiman, <a href="https://arxiv.org/abs/2302.04844" target="_blank">The Gradient of Generative AI Release: Methods and Considerations</a>, FAccT, 2023.</p>

<h3><a href="https://arxiv.org/abs/2106.10328" target="_blank">Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets</a></h3>
<h4>A proposed process for crafting a small, curated dataset on to adapt language model behavior to cultural context via fine-tuning. Accepted to NeurIPS 2021 as a spotlight presentation (less than 3% of papers).</h4>
<p>Research: Solaiman and Dennison, <a href="https://arxiv.org/abs/2106.10328" target="_blank">Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets</a>, NeurIPS, 2021.</p>
    
<h3><a href="https://arxiv.org/abs/1908.09203" target="_blank">Release Strategies and the Social Impacts of Language Models</a></h3>
<h4>OpenAI's policy research paper on language model GPT-2; insights on misuse, detection, and biases; and its staged release and recommendations for responsible publicaiton.</h4>
<p>Research: Solaiman et al, <a href="https://arxiv.org/abs/1908.09203" target="_blank">Release Strategies and the Social Impacts of Language Models</a>, OpenAI, 2019.</p>

<h2>AI & Public Policy</h2>
    
<h3><a href="https://www.bkmla.org/studentfellowship-community" target="_blank">Assembly Student Fellowship (formerly known as Techtopia)</a></h3>
<h4>Based in the Harvard Berkman Klein Center for Internet and Society, students from across Harvard schools come together for seminars and research</h4>
<p>Research: A Policymaker's Guide to Automated Decision Making Systems (unpublished)</p>

<h3><a href="https://carrcenter.hks.harvard.edu/event/human-rights-ethics-and-artificial-intelligence-challenges-next-70-years-universal" target="_blank">Human Rights, Ethics, and Artificial Intelligence</a></h3>
<h4>Conference on the effects of AI on human rights in the near future.</h4>
<p>Watch an overview of the Techtopia seminar <a href="https://carrcenter.hks.harvard.edu/news/discussing-human-rights-ethics-and-artificial-intelligence-harvard-techtopia-students" target="_blank">here</a>.</p>
<p>Watch conference presentation <a href="https://youtu.be/Q1r448nZ7DA?t=1035" target="_blank">here</a>.</p>
<p>View conference report <a href="https://carrcenter.hks.harvard.edu/files/cchr/files/aitechconferencereport_jan14.pdf" target="_blank">here</a>.</p>

<h3><a href="https://www.ftc.gov/news-events/press-releases/2018/11/ftc-hearings-competition-consumer-protection-21st-century-0" target="_blank">FTC Hearings on Competition and Consumer Protection in the 21st Century</a></h3>
<h4>The hearings address the use of algorithms, artificial intelligence, and predictive analytics in business decisions and conduct.</h4>
<p>Memo: <a href="https://www.ftc.gov/system/files/documents/public_comments/2019/02/ftc-2018-0101-d-0009-163777.pdf" target="_blank">Consumer Protection in AI/ML</a></p>

<br>
<h2>U.S. Election Cybersecurity</h2>
<h3><a href="https://www.belfercenter.org/D3P/" target="_blank">Defending Digital Democracy Project</a></h3>
<h4>Based in the Harvard Kennedy School's Belfer Center for Science and International Affairs, this operational project works with U.S. state and local election officials and partnering organizations to defend the U.S. election system and democratic process from cyberattack and foreign interference.</h4>
<p>Publication: <a href="https://www.belfercenter.org/publication/defending-vote-casting-using-blockchain-based-mobile-voting-applications-government" target="_blank">Defending Vote Casting</a></p>
<p>An analysis of blockchain-based mobile voting in U.S. elections.</p>
<p>Publication: <a href="https://www.belfercenter.org/publication/national-counter-information-operations-strategy" target="_blank">National Counter-Information Operations Strategy</a></p>
<p>A report on combating misinformation.</p>

    <footer>
      <ul class="meta inline-list">
        <li><a href="https://www.linkedin.com/in/irene-solaiman/" target="_blank">linkedin</a></li>
        <li><a href="" target="_blank">email: contact AT irenesolaiman.com</a></li>
        <li><a href="https://twitter.com/irenesolaiman" target="_blank">twitter</a></li>
      </ul>
    </footer>
</body>

</html>
